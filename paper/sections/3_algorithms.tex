%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Algorithms
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% \documentclass[../paper.tex]{subfiles}
% \begin{document}
    This section provides an overview of the partitioning algorithms implemented
    in the framework, detailing their underlying principles.
    Through illustrative examples and visual representations, we highlight the behavior of each algorithm.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Geometric-based
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Geometric-based partitioning algorithms}
    \label{subsec:geo}
    This class of bisection algorithms operates under the assumption that the geometric layout of the
    graph is known.
    These algorithms exploit spatial information of the vertices to guide the
    partitioning process, aiming to minimize edge cuts while preserving geometric
    coherence~\cite{doi:10.1137/S1064827594275339}.
    This approach is particularly well suited for applications where the graph structure
    arises from physical systems, such as finite element meshes in numerical computing,
    where the underlying geometry directly influences computational efficiency~\cite{buluc2015recentadvancesgraphpartitioning}. Unless stated otherwise, all function calls presented in this section take as input a graph adjacency matrix \texttt{A} and a node coordinate matrix \texttt{coords}, and return a vector assigning each node to partition 1 or 2.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    
    \subsubsection{Coordinate bisection}
    \label{subsubsec:coord}
    Coordinate bisection seeks a hyperplane orthogonal to one of the coordinate axes that partitions the graph's vertices into two subsets of approximately equal size
    while minimizing the edge cut.
    The algorithm computes the median $\bar{x}_j$ of each coordinate $x_j$,
    dividing all graph vertices into two groups: one containing vertices with $x_j \leq \bar{x}_j$ and the other $x_j > \bar{x}_j$. The edge cut is then evaluated for each coordinate axis, and the
    partitioning is performed along the axis that yields the smallest edge cut.
    This process in a $d$-dimensional space is summarized in \Cref{alg:coord}, with a two-dimensional example illustrated in \Cref{fig:coord}.
    The complexity of coordinate bisection is $O(d(n+m))$ when using linear-time median selection or $O(d(n \log n + m))$ with sorting-based medians~\cite{10.5555/1614191}, where $n$ is the number of vertices, and $m$ the number of edges.

    
    \input{figures/coordinates_bisect_fig}
    \input{algorithms/coordinate_bisect_alg}
    
    The coordinate bisection method in \texttt{GraphLab.jl} can be invoked using the following command:
    
    \begin{lstlisting}[language=Julia]
    GraphLab.part_coordinate(A, coords)
    \end{lstlisting}
    
    The coordinate bisection algorithm is computationally efficient and conceptually simple.
    However, its effectiveness is strongly influenced by the choice of coordinate system.
    A mere rotation of the coordinate axes can lead to significantly different partitioning results,
    as the algorithm strictly aligns the division with the coordinate axes.
    This sensitivity may lead to suboptimal partitions, particularly in cases where the problem geometry
    is not naturally aligned with the axes.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   
    \subsubsection{Inertial bisection}
    The inertial bisection mitigates the axis-alignment limitation of coordinate bisection by
    allowing the dividing hyperplane to be orthogonal to a direction determined by the
    distribution of vertices rather than a fixed coordinate axis. Physically, this direction corresponds to the axis of minimal rotational inertia~\cite{elsner1997graph}, ensuring that
    partitioning is guided by the intrinsic geometry of the data rather than an arbitrary reference frame.
    
    In two dimensions, the dividing hyperplane is
    represented by a line $l$ that minimizes the sum
    of squared distances from the vertices to the line. The algorithm first determines the center of mass of the vertex set,
    \begin{equation}
      \bar{P}=(\bar{x}, \bar{y}), \quad \text{where} \quad  \bar{x} = \frac{1}{n}\sum_{i=1}^n x_i, \quad \bar{y} = \frac{1}{n}\sum_{i=1}^n y_i\text{.}
    \end{equation}
    It then defines a unit direction vector $\mathbf{u}=[u_1, u_2]^T$, such that 
    $\|\mathbf{u}\|_2 = \sqrt{u_1^2+u_2^2} = 1$.
    The parametric equation
    of the bisecting line is given by
    $l(\lambda) = \{\bar{P} + \lambda \mathbf{u}  \mid \lambda \in \mathbb{R} \}$.
    
    \input{figures/inertial_fig}
    
    % The coordinates of the center of mass $\bar{P}$, which lies on the line $l$, are given by
    
    
    To determine the optimal orientation of the bisecting hyperplane, the unit direction vector $\mathbf{u}$ is chosen to minimize the sum of the squared
    distances from the vertices to the line. In the case of a two-dimensional graph embedding, this reads:
    
    \input{math/inertial_eq}
    
    Here, $\mathbf{M}$ is a symmetric matrix, and its smallest eigenvalue corresponds to the minimal sum of the squared distances. Consequently, the optimal direction vector $\mathbf{u}$ is given by the
    normalized eigenvector associated with the smallest eigenvalue of
    $\mathbf{M}$~\cite{elsner1997graph}. This choice ensures that the partitioning hyperplane is aligned with the principal axis of least variance, making the algorithm robust to coordinate system transformations. The full procedure for bisecting a graph using inertial partitioning is summarized in \Cref{alg:inert}.
    The inertial bisection runs in time $O(nd+m+d^3)$, which simplifies to $O(n+m)$ in fixed spatial dimension.
    
    \input{algorithms/inertial_alg}

    To perform inertial bisection with \texttt{GraphLab.jl} on a graph, use:

    \begin{lstlisting}[language=Julia]
    GraphLab.part_inertial(A, coords)
    \end{lstlisting}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsubsection{Random sphere bisection}
    \label{sub:rand_sphere}

    The random sphere method~\cite{doi:10.1137/S1064827594275339} partitions a graph
    by exploiting spatial information to identify separators aligned with the intrinsic geometry of the vertex
    distribution.
    Unlike axis-aligned or inertia-based approaches,
    it employs randomized geometric projections to discover low-cut partitions.
    
    Given vertex coordinates $P_i = (x_1, \dots, x_d)_i$, the algorithm first computes the center of mass $\bar{P}$ and normalizes the coordinates as
    \begin{equation}
        \tilde{P}_i=\frac{P_i-\bar{P}}{\max_j{|P_j-\bar{P}|}},
    \end{equation}
    so that the distribution is centered at the origin and confined within a unit-scale region.
    Each normalized point $\tilde{P}_i$ is then mapped to the unit sphere,
    $Z_i \in \mathcal{S}^d \subset{\mathbb{R}^{d+1}}$, via stereographic projection.

    To identify separators, the algorithm selects $s$ random center points on the sphere.
    Each center $c$ is computed as the coordinate-wise median of a randomly sampled subset of vertices and then moved to the origin through a conformal transformation of the sphere.
    For each transformed configuration, several random unit directions $u$ are sampled, and a candidate spherical cut is generated as

    \begin{equation}
        \mathcal{V}_1= \{ i \mid \langle Z_i, u \rangle \leq 0 \}, \quad \mathcal{V}_2 = \{ i \mid \langle Z_i, u \rangle > 0 \},
    \end{equation}
    The corresponding edge cut is evaluated, and the partition with the smallest cut is retained.

    % 
    \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{images/rsphere.png}
    \caption{
    % Spectral embedding and random sphere partitioning: the graph is first embedded into a 2-dimensional
    % spectral space using the eigenvectors associated with the second and third smallest eigenvalues of the graph Laplacian. A separator (shown in red)
    % is then selected using the randomized sphere method and mapped back onto original graph.
    Random sphere partitioning: the 2D coordinates of \texttt{mesh1e1}~\cite{10.1145/2049662.2049663} are normalized and stereographically lifted to the sphere $\mathcal{S}^2 \subset \mathbb{R}^3$, where a centerpoint $c$ is computed and mapped to the origin via a conformal transformation. A direction $\mathbf{u}$ defining a circle separator (shown in red) is then selected, partitioning the spherical embedding. The resulting partition is projected onto the original layout. 
    }
    \label{fig:rsphere}
    \end{figure}
    % 

    In addition to spherical separators, the algorithm also considers random linear cuts in the original
    Euclidean space, defined by hyperplanes
    orthogonal to random directions and positioned at the median projected vertex coordinates.
    The final output is the spherical or linear bisection minimizing the total edge cut.

    The random spherical bisection runs in $O(sr(nd+m))$, where $s$ is the number of random centers and $r$ the number of random directions per center. For fixed $d$, $s$, and $r$, this reduces to $O(n+m)$.
    The algorithm is described in \Cref{alg:sphere} and can be applied with:

    \begin{lstlisting}[language=Julia]
    GraphLab.part_randsphere(A, coords; ntrials)
    \end{lstlisting}

    An optional argument \texttt{ntrials} specifies the number of random directions to try.
    % A 2-dimensional geometric illustration of the spherical bisection procedure is provided in \Cref{fig:rsphere}.
    A geometric illustration of the random sphere bisection procedure, applied to 2-dimensional input coordinates and visualized on the sphere $\mathcal{S}^2 \subset \mathbb{R}^3$, is provided in \Cref{fig:rsphere}.

    \input{algorithms/sphere_alg}
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%   
    \subsubsection{Adaptive space-filling curves}
    \label{sub:sfc}
    Space-filling curves (SFCs) provide a continuous, one-dimensional traversal
    of multidimensional space that preserves spatial locality.
    In the context of partitioning, SFCs induce a linear ordering of the data
    points, enabling recursive division into balanced and spatially coherent subregions. We implement an adaptive SFC traversal over a
    hierarchical spatial decomposition to generate partitions that reflect the geometric structure of the input graph~\cite{Sasidharan15, sasidharan2015space}.

    The algorithm, presented in \Cref{alg:adaptive_sfc}, performs coordinate bisection as introduced in \Cref{subsubsec:coord} based on spatial distribution of the graph's vertices, using an adaptive SFC traversal.
    It begins by constructing a $k$-dimensional tree ($k$-d tree) of the vertex coordinates $P$, a binary space-partitioning structure that recursively subdivides the domain along axis-aligned hyperplanes. At each node of the $k$-d tree, the splitting axis is chosen as the direction of maximum spatial extent, and the point set $P$ is recursively divided until each leaf contains a single point.

    % It begins by constructing a k-dimensional tree (KD-tree) of the vertex coordinates P, a binary space-partitioning structure that recursively subdivides the coordinate space along selected axes. At each node, the splitting axis is chosen according to the direction of maximum spatial extent, and the point set P is recursively divided until each leaf contains a single point.

    Once the tree is built, an SFC traversal induces a linear order of the leaves by visiting spatial regions in a directionally consistent, locality-preserving manner.
    At each recursive step, the traversal maintains entry and exit directions that specify how the curve enters and leaves a region, ensuring a continuous path between adjacent subregions.
    The coordinates associated with each leaf are collected in traversal order, producing a one-dimensional sequence of vertices.
    This process is illustrated in \Cref{fig:sfc}.

    % Once the tree is built, an adaptive SFC traversal defines a linear order of the leaves by visiting spatial regions in a directionally consistent, locality-preserving manner. At each recursive step, the traversal maintains entry and exit directions that specify how the curve enters and leaves a region, ensuring continuity between adjacent subregions. The coordinates associated with each leaf are then collected in traversal order, producing a one-dimensional sequence. This process is illustrated in \Cref{fig:sfc}.

    The resulting sequence is subsequently partitioned into $k$ contiguous segments of approximately equal size, producing $k$ spatially coherent and locality-preserving partitions. A key advantage of this method over other partitioning approaches is that, once the traversal is computed, partitioning into an arbitrary number of parts becomes a trivial post-processing step: splitting the ordered node list into contiguous segments.
    Construction of the adaptive spatial tree requires $O(n\log n)$ time, and the subsequent SFC traversal and linear partition each cost $O(n)$, giving an overall complexity of $O(n\log n)$.

    Adaptive space-filling curve partitioning in \texttt{GraphLab.jl} is invoked as follows, with an optional argument \texttt{k} specifying the number of partitions:
    
    \begin{lstlisting}[language=Julia]
    GraphLab.part_adaptive_sfc(A, coords, k)
    \end{lstlisting}

    \input{figures/sfc_fig}
    
    \input{algorithms/sfc_partitioning_alg}
    

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Non-geometric-based
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Non-geometric-based partitioning algorithms}
    \label{subsec:non-geo}
    Geometric-based partitioning algorithms
    % are efficient techniques for partitioning meshes, particularly
    % when spatial adjacency plays a key role in connectivity. However, these algorithms have inherent limitations.
    % They
    rely on the premise that the graph's vertices exhibit a spatial relationship, a condition that does not
    hold in all contexts, such as social~\cite{Newman_2013} or biological~\cite{10.1093/nar/gkx1313} networks.
    
    To accommodate a broader range of applications, alternative algorithms that do not rely on geometric information
    have been developed. Notable examples include the Kernighan-Lin~\cite{6771089} and graph-growing algorithms~\cite{doi:10.1137/S1064827595287997},
    both well suited for partitioning graphs lacking explicit spatial structure.
    Among these, spectral bisection leverages
    the eigenvalues and eigenvectors of the graph Laplacian matrix to inform partitioning decision~\cite{fiedler75}.
    In this subsection, we focus
    on the implementation and application of spectral bisection, detailing its computational properties and advantages over geometry-dependent algorithms.
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%    
    \subsubsection{Spectral bisection}\label{sub:spec} The spectral bisection algorithm partitions a graph
    by leveraging the eigenvector corresponding to the second-smallest eigenvalue,
    commonly known as the Fiedler vector, of the graph's Laplacian matrix $\mathbf{L}$.
    The combinatorial graph Laplacian matrix is defined as $\mathbf{L} = \mathbf{D}-\mathbf{A}$,
    where $\mathbf{D}$ is the degree and $\mathbf{A}$ is the adjacency matrix.
    The graph Laplacian $\mathbf{L}$ is a symmetric, positive semi-definite matrix, which admits an orthonormal basis of eigenvectors $\mathbf{u}^{(i)}$ with corresponding nonnegative eigenvalues
    $\lambda^{(i)} \ge 0$.
    The smallest eigenvalue is
    $\lambda^{(1)} = 0$, and its associated eigenvector
    $\mathbf{u}^{(1)} = c\mathbf{1}$, where $c$ is a constant and $\mathbf{1}$ the all one’s vector corresponding to the trivial solution, in which all vertices of a connected graph belong to a single connected component.
    The eigenvector $\mathbf{u}^{(2)}$
    associated with the second-smallest eigenvalue $\lambda^{(2)}$, known as the Fiedler vector~\cite{fiedler75}, provides a one-dimensional embedding of the graph that reflects its connectivity structure, as illustrated in~\Cref{fig:spec}. Each vertex $v_i$ is assigned the scalar value $\mathbf{u}_i^{(2)}$, and vertices with similar values tend to be more tightly connected within the graph. A bisection is obtained by
    thresholding $\mathbf{u}^{(2)}$:
    \begin{equation}
        \mathcal{V}_1 = \{v_i \mid \mathbf{u}_i^{(2)} \leq \epsilon\}, \quad
        \mathcal{V}_2 = \{v_i \mid \mathbf{u}_i^{(2)} > \epsilon\},
    \end{equation}
    where $\epsilon=0$ yields a cut that approximately minimizes the edge weight between subsets, and $\epsilon=\operatorname{median}\big(\mathbf{u}^{(2)}_1, \dots, \mathbf{u}^{(2)}_n\big)$ enforces a balanced partition.
    % Each node $v_i$ is associated with the corresponding entry $\mathbf{u}^{(2)}_i$ of the Fiedler vector. The partition is performed by thresholding these values:
    % \begin{itemize}
    %     \item A threshold at zero yields two roughly balanced subsets while minimizing the edge cut.
    %     \item A threshold at $\mathbf{u}^{(2)}$ results in two strictly equal-sized partitions.
    % \end{itemize}
    Spectral bisection is dominated by the Fiedler vector computation. Forming the Laplacian from a given graph costs $O(n + m)$~\cite{Pasadakis23}, while ARPACK's Lanczos method~\cite{lehoucq1998arpack, lanczos1950iteration} extracts the second eigenpair in $O(mt)$ time~\cite{golub2013matrix}, where $t$ is the number of iterations. Thus the total complexity is $O(mt)$, with all other operations linear.
    The spectral algorithm, outlined in \Cref{alg:spec}, can be executed with:
    
    \input{figures/spectral_fig}
    
    \input{algorithms/spectral_alg}

    % Spectral bisection method implemented in \texttt{GraphLab.jl} can be executed with:

    \begin{lstlisting}[language=Julia]
    GraphLab.part_spectral(A)
    \end{lstlisting}

    Its sole input is the adjacency matrix \texttt{A} and its output a vector assigning each node to partition $1$ or $2$.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Hybrid bisection
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Hybrid partitioning algorithms}
    \label{subsec:hybrid}
    Combining the random sphere bisection and the spectral partitioning described in \ref{sub:rand_sphere} and \ref{sub:spec}, hybrid bisection extends spectral methods with
    a geometric layer to enhance partitioning quality, particularly in graphs with an underlying spatial structure. It begins by computing a spectral embedding of the graph, where each vertex $v_i$ is mapped to a point 
    \begin{equation}
        \mathbf{z}_i = \left( \mathbf{u}_i^{(2)}, \dots, \mathbf{u}_i^{(k+1)}\right) \in \mathbb{R}^k,
    \end{equation}
    using the first $k$ nontrivial eigenvectors of the Laplacian matrix. This embedding encodes the global
    connectivity structure of the graph in a low-dimensional space, where geometric separations of the embedded points with the random sphere method lead to sparse graph cuts. This process performs a geometric search over separators, guided by the spectral structure of the graph. The figure~\Cref{fig:spectral-embedding} illustrates the case with $k=2$, where the embedding uses the first two non-trivial Laplacian eigenvectors.
    % 
    \begin{figure}[t]
    \centering
    \includegraphics[width=1.0\linewidth]{images/airfoil_ev.drawio.png}
    \caption{Spectral embedding and random sphere partitioning: the \texttt{airfoil1}~\cite{10.1145/2049662.2049663} graph is first embedded into a 2-dimensional
    spectral space using the eigenvectors associated with the second and third smallest eigenvalues of the graph Laplacian. A separator (shown in red)
    is then selected using the randomized sphere method and mapped back onto original graph.}
    \label{fig:spectral-embedding}
    \end{figure}
    % 
    The hybrid method leverages the algebraic properties of spectral embeddings and effectiveness of random sphere cuts to generate balanced and spatially localized partitions. It's overall complexity is dominated by the spectral stage, $O(mt_k)$ for sparse graphs, where $t_k$ is the number of Lanczos iterations required to compute $k$ nontrivial eigenvectors.

    Geometric spectral partitioning in \texttt{GraphLab.jl} can be executed with:

    \begin{lstlisting}[language=Julia]
    GraphLab.part_geospectral(A; ev=d)
    \end{lstlisting}

    In addition to the adjacency matrix \texttt{A}, it optionally accepts $\texttt{ev}=d$, i.e., the number of nontrivial Laplacian eigenvectors to use for embedding (default: 2).
    
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
% Recursive bisection
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
    \subsection{Recursive bisection and nested dissection}
    Recursive bisection and nested dissection are techniques that rely on recursively splitting a graph into smaller subgraphs. While recursive bisection is primarily used to generate multiple balanced partitions, nested dissection applies a recursive strategy to reduce fill-in during sparse matrix factorization~\cite{George73}. This section outlines both methods and their respective algorithmic formulations.
    \subsubsection{Recursive bisection}
    \label{subsub:rec_bi}
    A straightforward and effective strategy for partitioning a graph into $p = 2^q$ parts,
    where $q$ is a positive integer, is recursive bisection, as presented in \Cref{alg:recursive}.
    This algorithm iteratively applies graph bisection, progressively
    subdividing the graph into smaller subgraphs.
    In \texttt{GraphLab.jl}, recursive bisection can be used with any of the bisection algorithms presented in \Cref{subsec:geo,subsec:non-geo}.
    The algorithm is built around a recursive function, \texttt{Recursion}, which takes as inputs:
    \begin{itemize}
        \item $C'$, the current subgraph to be partitioned,
        \item $p'$, the number of partitions into which $C'$ will be further divided, and
        \item $\mathrm{idx}$, an integer tracking the position of the first part of $C'$ in the final partitioning results.
    \end{itemize}
    
    At each recursive step, the subgraph $C'$ is bisected into two approximately balanced parts. The process continues
    until the desired number of partitions, $p = 2^q$, is obtained.
    The total cost is $O(T_{\text{bisect}}(n, m) \log p)$, where $ T_{\text{bisect}}(n, m)$ is the cost of a single bisection method.
    This recursive strategy results in a structured,
    hierarchical decomposition of the graph, making it particularly well suited for load balancing and for reducing communication overhead in parallel finite element and finite difference implementations~\cite{doi:10.1137/S1064827593255135}.
    
    \input{algorithms/recursive_alg}

    \texttt{GraphLab.jl} provides a recursive interface for all partitioning algorithms described in \Cref{sec:algo}, which can be invoked with:

    \begin{lstlisting}[language=Julia]
    GraphLab.recursive_bisection(method, k, 
        A, coords)
    \end{lstlisting}

    Here, \texttt{method} is any partitioning function available in the package, \texttt{k} is the desired number of partitions (automatically rounded up to the nearest power of two if needed), \texttt{A} is the graph's adjacency matrix, and \texttt{coords} is an optional argument (default: \texttt{nothing}) used only for coordinate-based methods. The function returns a vector assigning each node a label from 1 to \texttt{k}, indicating its partition membership.


    \subsubsection{Nested dissection}
    The nested dissection ordering algorithm is a multilevel heuristic designed to minimize fill-in, i.e., the creation of nonzero entries during sparse matrix factorizations~\cite{George73}.
    It recursively partitions a graph $G$ through the identification of balanced vertex separators, which are removed to decompose $G$ into disconnected components. The same procedure is then applied recursively to each subgraph.
    Unlike standard recursive bisection, which directly bisects the graph into two parts, nested dissection introduces an intermediate step: the explicit computation of a node separator whose removal divides the problem into independent subproblems.
    To compute the separator, border vertices are first identified between the two subdomains resulting from the initial bisection. These vertices induce a bipartite graph, in which edges represent adjacency across the partition boundary. A maximum matching is then computed on this bipartite graph and a minimum vertex cover can be derived from it~\cite{bondy1976graph, storer2012introduction}, providing an efficient approximation of a small separator. The selected separator vertices are removed, and the nested dissection proceeds recursively on the resulting components.
    The final ordering $\pi$ places all separator vertices after the recursively ordered interior vertices, yielding a global vertex ordering that reveals a hierarchical block structure in the reordered matrix.
    The complexity of nested dissection is $O(T_{\text{bisect}}(n,m) \log n)$, where $T_{\text{bisect}}(n,m)$ denotes the cost of a single graph bisection.
    The overall process is outlined in \Cref{alg:nested_dis}.

    This strategy is widely used in the symbolic
    factorization phase of sparse direct solvers, where it
    facilitates the construction of efficient elimination
    trees and reduces both fill-in and memory overhead
    during numerical factorization~\cite{Bollhöfer2020}.
    Nested dissection can be implemented using the
    partitioning methods presented in \Cref{subsec:geo}
    and \Cref{subsec:non-geo} for computing the node
    separator. \Cref{fig:nd_perm_results} illustrates how
    different separator methods permute the adjacency
    matrix into a
    hierarchy of interior and separator blocks, yielding
    distinctive banded or clustered nonzero patterns.
    The differences between the separator methods are
    reflected in the number of nonzero entries in the
    Cholesky factor~\cite{George73}.
    
    \input{figures/nd}
    


    \input{algorithms/nested_alg}

    The nested dissection provided by \texttt{GraphLab.jl} is called using:

    \begin{lstlisting}[language=Julia]
    GraphLab.nested_dissection(A, method; 
        coords, minsep=5)
    \end{lstlisting}

    The inputs are the adjacency matrix \texttt{A}, any partitioning \texttt{method} from \texttt{GraphLab.jl}, and the node coordinates \texttt{coords} if required by the partitioner. An optional argument \texttt{minsep} specifies the minimum separator size (default: 5). The output is a permutation vector representing the nested dissection ordering.
    
% \end{document}